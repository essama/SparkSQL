{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean calculation in 2 rdds\n",
    "import random\n",
    "rdd1 = sc.parallelize (range(100))\n",
    "rdd2 = sc.parallelize (list(reversed(range(100))))\n",
    "\n",
    "mean1 = rdd1.sum()/float(rdd1.count())\n",
    "mean2 = rdd2.sum()/float(rdd2.count())\n",
    "\n",
    "mean1\n",
    "mean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-833.25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covariance calculation\n",
    "rdd3= rdd1.zip(rdd2)\n",
    "cov= rdd3.map(lambda x : (x[0]-mean1)*(x[1]-mean2)).sum()/rdd3.count()\n",
    "cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the standard deviation\n",
    "from math import sqrt \n",
    "n=rdd3.count()\n",
    "sdx = sqrt(rdd1.map(lambda x : pow(x-mean1,2)).sum()/n)\n",
    "sdy = sdY = sqrt(rdd2.map(lambda x : pow(x-mean2,2)).sum()/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the correlation\n",
    "from math import sqrt\n",
    "corr = cov/ (sdx*sdy)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.         -1.         -0.00944494]\n",
      " [ 1.          1.         -1.         -0.00944494]\n",
      " [-1.         -1.          1.          0.00944494]\n",
      " [-0.00944494 -0.00944494  0.00944494  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#correlation matrix of 4 arrays\n",
    "from pyspark.mllib.stat lists Statistics\n",
    "import random\n",
    "column1 = sc.parallelize(range(100))\n",
    "column2 = sc.parallelize(range(100,200))\n",
    "column3 = sc.parallelize(list(reversed(range(100))))\n",
    "column4 = sc.parallelize(random.sample(range(100),100))\n",
    "data = column1.zip(column2).zip(column3).zip(column4).map(lambda a_b_c_d : (a_b_c_d[0][0][0],a_b_c_d[0][0][1],a_b_c_d[0][1],a_b_c_d[1]) ).map(lambda a_b_c_d : [a_b_c_d[0],a_b_c_d[1],a_b_c_d[2],a_b_c_d[3]])\n",
    "print(Statistics.corr(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 with Spark",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
